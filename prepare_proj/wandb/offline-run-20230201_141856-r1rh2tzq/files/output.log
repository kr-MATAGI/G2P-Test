  0%|                                                                                       | 0/2500 [00:00<?, ?it/s]Traceback (most recent call last):
  File "run_kogpt.py", line 129, in <module>
    trainer.train()
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/trainer.py", line 1409, in train
    return inner_training_loop(
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/trainer.py", line 1651, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/trainer.py", line 2345, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/trainer.py", line 2377, in compute_loss
    outputs = model(**inputs)
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py", line 848, in forward
    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1164, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
ValueError: Expected input batch_size (96) to match target batch_size (1088).
[31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mTraceback (most recent call last)[31m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
[31mâ”‚[39m /home/ailab/ë°”íƒ•í™”ë©´/KT_IPA/G2P-Test/prepare_proj/[1mrun_kogpt.py[22m:[94m129[39m in [92m<module>[39m                   [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   126 â”‚   â”‚   â”‚   data_collator=data_collator,                                                   [31mâ”‚
[31mâ”‚[39m   127 â”‚   â”‚   )                                                                                  [31mâ”‚
[31mâ”‚[39m   128 â”‚   â”‚                                                                                      [31mâ”‚
[31mâ”‚[39m [31mâ± [39m129 â”‚   â”‚   trainer.train()                                                                    [31mâ”‚
[31mâ”‚[39m   130 â”‚   â”‚   trainer.save_model(args.output_dir)                                                [31mâ”‚
[31mâ”‚[39m   131 â”‚                                                                                          [31mâ”‚
[31mâ”‚[39m   132 â”‚   [94mif[39m args.evaluate:                                                                      [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/[1mtrainer.py[22m:[94m1409[39m in  [31mâ”‚
[31mâ”‚[39m [92mtrain[39m                                                                                            [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1406 â”‚   â”‚   inner_training_loop = find_executable_batch_size(                                 [31mâ”‚
[31mâ”‚[39m   1407 â”‚   â”‚   â”‚   [96mself[39m._inner_training_loop, [96mself[39m._train_batch_size, args.auto_find_batch_size  [31mâ”‚
[31mâ”‚[39m   1408 â”‚   â”‚   )                                                                                 [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1409 â”‚   â”‚   [94mreturn[39m inner_training_loop(                                                       [31mâ”‚
[31mâ”‚[39m   1410 â”‚   â”‚   â”‚   args=args,                                                                    [31mâ”‚
[31mâ”‚[39m   1411 â”‚   â”‚   â”‚   resume_from_checkpoint=resume_from_checkpoint,                                [31mâ”‚
[31mâ”‚[39m   1412 â”‚   â”‚   â”‚   trial=trial,                                                                  [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/[1mtrainer.py[22m:[94m1651[39m in  [31mâ”‚
[31mâ”‚[39m [92m_inner_training_loop[39m                                                                             [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1648 â”‚   â”‚   â”‚   â”‚   â”‚   [94mwith[39m model.no_sync():                                                 [31mâ”‚
[31mâ”‚[39m   1649 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   tr_loss_step = [96mself[39m.training_step(model, inputs)                  [31mâ”‚
[31mâ”‚[39m   1650 â”‚   â”‚   â”‚   â”‚   [94melse[39m:                                                                     [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1651 â”‚   â”‚   â”‚   â”‚   â”‚   tr_loss_step = [96mself[39m.training_step(model, inputs)                      [31mâ”‚
[31mâ”‚[39m   1652 â”‚   â”‚   â”‚   â”‚                                                                             [31mâ”‚
[31mâ”‚[39m   1653 â”‚   â”‚   â”‚   â”‚   [94mif[39m (                                                                      [31mâ”‚
[31mâ”‚[39m   1654 â”‚   â”‚   â”‚   â”‚   â”‚   args.logging_nan_inf_filter                                           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/[1mtrainer.py[22m:[94m2345[39m in  [31mâ”‚
[31mâ”‚[39m [92mtraining_step[39m                                                                                    [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   2342 â”‚   â”‚   â”‚   [94mreturn[39m loss_mb.reduce_mean().detach().to([96mself[39m.args.device)                    [31mâ”‚
[31mâ”‚[39m   2343 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m   2344 â”‚   â”‚   [94mwith[39m [96mself[39m.compute_loss_context_manager():                                         [31mâ”‚
[31mâ”‚[39m [31mâ± [39m2345 â”‚   â”‚   â”‚   loss = [96mself[39m.compute_loss(model, inputs)                                       [31mâ”‚
[31mâ”‚[39m   2346 â”‚   â”‚                                                                                     [31mâ”‚
[31mâ”‚[39m   2347 â”‚   â”‚   [94mif[39m [96mself[39m.args.n_gpu > [94m1[39m:                                                           [31mâ”‚
[31mâ”‚[39m   2348 â”‚   â”‚   â”‚   loss = loss.mean()  # mean() to average on multi-gpu parallel training        [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/[1mtrainer.py[22m:[94m2377[39m in  [31mâ”‚
[31mâ”‚[39m [92mcompute_loss[39m                                                                                     [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   2374 â”‚   â”‚   â”‚   labels = inputs.pop([33m"labels"[39m)                                                 [31mâ”‚
[31mâ”‚[39m   2375 â”‚   â”‚   [94melse[39m:                                                                             [31mâ”‚
[31mâ”‚[39m   2376 â”‚   â”‚   â”‚   labels = [94mNone[39m                                                                 [31mâ”‚
[31mâ”‚[39m [31mâ± [39m2377 â”‚   â”‚   outputs = model(**inputs)                                                         [31mâ”‚
[31mâ”‚[39m   2378 â”‚   â”‚   # Save past state if it exists                                                    [31mâ”‚
[31mâ”‚[39m   2379 â”‚   â”‚   # TODO: this needs to be fixed and made cleaner later.                            [31mâ”‚
[31mâ”‚[39m   2380 â”‚   â”‚   [94mif[39m [96mself[39m.args.past_index >= [94m0[39m:                                                     [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m1130[39m  [31mâ”‚
[31mâ”‚[39m in [92m_call_impl[39m                                                                                    [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1127 â”‚   â”‚   # this function, and just call forward.                                           [31mâ”‚
[31mâ”‚[39m   1128 â”‚   â”‚   [94mif[39m [95mnot[39m ([96mself[39m._backward_hooks [95mor[39m [96mself[39m._forward_hooks [95mor[39m [96mself[39m._forward_pre_hooks [95mo[39m  [31mâ”‚
[31mâ”‚[39m   1129 â”‚   â”‚   â”‚   â”‚   [95mor[39m _global_forward_hooks [95mor[39m _global_forward_pre_hooks):                   [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1130 â”‚   â”‚   â”‚   [94mreturn[39m forward_call(*[96minput[39m, **kwargs)                                         [31mâ”‚
[31mâ”‚[39m   1131 â”‚   â”‚   # Do not call functions when jit is used                                          [31mâ”‚
[31mâ”‚[39m   1132 â”‚   â”‚   full_backward_hooks, non_full_backward_hooks = [], []                             [31mâ”‚
[31mâ”‚[39m   1133 â”‚   â”‚   [94mif[39m [96mself[39m._backward_hooks [95mor[39m _global_backward_hooks:                                [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/models/gptj/[1mmodelin[22m [31mâ”‚
[31mâ”‚[39m [1mg_gptj.py[22m:[94m848[39m in [92mforward[39m                                                                         [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m    845 â”‚   â”‚   â”‚   shift_labels = labels[..., [94m1[39m:].contiguous()                                   [31mâ”‚
[31mâ”‚[39m    846 â”‚   â”‚   â”‚   # Flatten the tokens                                                          [31mâ”‚
[31mâ”‚[39m    847 â”‚   â”‚   â”‚   loss_fct = CrossEntropyLoss()                                                 [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 848 â”‚   â”‚   â”‚   loss = loss_fct(shift_logits.view(-[94m1[39m, shift_logits.size(-[94m1[39m)), shift_labels.v  [31mâ”‚
[31mâ”‚[39m    849 â”‚   â”‚   â”‚                                                                                 [31mâ”‚
[31mâ”‚[39m    850 â”‚   â”‚   â”‚   loss = loss.to(hidden_states.dtype)                                           [31mâ”‚
[31mâ”‚[39m    851                                                                                           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m1130[39m  [31mâ”‚
[31mâ”‚[39m in [92m_call_impl[39m                                                                                    [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1127 â”‚   â”‚   # this function, and just call forward.                                           [31mâ”‚
[31mâ”‚[39m   1128 â”‚   â”‚   [94mif[39m [95mnot[39m ([96mself[39m._backward_hooks [95mor[39m [96mself[39m._forward_hooks [95mor[39m [96mself[39m._forward_pre_hooks [95mo[39m  [31mâ”‚
[31mâ”‚[39m   1129 â”‚   â”‚   â”‚   â”‚   [95mor[39m _global_forward_hooks [95mor[39m _global_forward_pre_hooks):                   [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1130 â”‚   â”‚   â”‚   [94mreturn[39m forward_call(*[96minput[39m, **kwargs)                                         [31mâ”‚
[31mâ”‚[39m   1131 â”‚   â”‚   # Do not call functions when jit is used                                          [31mâ”‚
[31mâ”‚[39m   1132 â”‚   â”‚   full_backward_hooks, non_full_backward_hooks = [], []                             [31mâ”‚
[31mâ”‚[39m   1133 â”‚   â”‚   [94mif[39m [96mself[39m._backward_hooks [95mor[39m _global_backward_hooks:                                [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/[1mloss.py[22m:[94m1164[39m in [31mâ”‚
[31mâ”‚[39m [92mforward[39m                                                                                          [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   1161 â”‚   â”‚   [96mself[39m.label_smoothing = label_smoothing                                            [31mâ”‚
[31mâ”‚[39m   1162 â”‚                                                                                         [31mâ”‚
[31mâ”‚[39m   1163 â”‚   [94mdef[39m [92mforward[39m([96mself[39m, [96minput[39m: Tensor, target: Tensor) -> Tensor:                           [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1164 â”‚   â”‚   [94mreturn[39m F.cross_entropy([96minput[39m, target, weight=[96mself[39m.weight,                         [31mâ”‚
[31mâ”‚[39m   1165 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      ignore_index=[96mself[39m.ignore_index, reduction=[96mself[39m.reduction,  [31mâ”‚
[31mâ”‚[39m   1166 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      label_smoothing=[96mself[39m.label_smoothing)                      [31mâ”‚
[31mâ”‚[39m   1167                                                                                           [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/[1mfunctional.py[22m:[94m3014[39m in   [31mâ”‚
[31mâ”‚[39m [92mcross_entropy[39m                                                                                    [31mâ”‚
[31mâ”‚[39m                                                                                                  [31mâ”‚
[31mâ”‚[39m   3011 â”‚   â”‚   )                                                                                 [31mâ”‚
[31mâ”‚[39m   3012 â”‚   [94mif[39m size_average [95mis[39m [95mnot[39m [94mNone[39m [95mor[39m reduce [95mis[39m [95mnot[39m [94mNone[39m:                                    [31mâ”‚
[31mâ”‚[39m   3013 â”‚   â”‚   reduction = _Reduction.legacy_get_string(size_average, reduce)                    [31mâ”‚
[31mâ”‚[39m [31mâ± [39m3014 â”‚   [94mreturn[39m torch._C._nn.cross_entropy_loss([96minput[39m, target, weight, _Reduction.get_enum(re  [31mâ”‚
[31mâ”‚[39m   3015                                                                                           [31mâ”‚
[31mâ”‚[39m   3016                                                                                           [31mâ”‚
[31mâ”‚[39m   3017 [94mdef[39m [92mbinary_cross_entropy[39m(                                                                 [31mâ”‚
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[1mValueError: [22mExpected input batch_size [1m(96)[22m to match target batch_size [1m(1088)[22m.