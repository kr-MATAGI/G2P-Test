  0%|                                                                                       | 0/2500 [00:00<?, ?it/s]Traceback (most recent call last):
  File "run_kogpt.py", line 129, in <module>
    trainer.train()
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/trainer.py", line 1409, in train
    return inner_training_loop(
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/trainer.py", line 1651, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/trainer.py", line 2345, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/trainer.py", line 2377, in compute_loss
    outputs = model(**inputs)
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py", line 848, in forward
    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1164, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
ValueError: Expected input batch_size (96) to match target batch_size (1088).
[31m╭─────────────────────────────── [39m[1mTraceback (most recent call last)[31m[22m ────────────────────────────────╮
[31m│[39m /home/ailab/바탕화면/KT_IPA/G2P-Test/prepare_proj/[1mrun_kogpt.py[22m:[94m129[39m in [92m<module>[39m                   [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m   126 │   │   │   data_collator=data_collator,                                                   [31m│
[31m│[39m   127 │   │   )                                                                                  [31m│
[31m│[39m   128 │   │                                                                                      [31m│
[31m│[39m [31m❱ [39m129 │   │   trainer.train()                                                                    [31m│
[31m│[39m   130 │   │   trainer.save_model(args.output_dir)                                                [31m│
[31m│[39m   131 │                                                                                          [31m│
[31m│[39m   132 │   [94mif[39m args.evaluate:                                                                      [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/[1mtrainer.py[22m:[94m1409[39m in  [31m│
[31m│[39m [92mtrain[39m                                                                                            [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m   1406 │   │   inner_training_loop = find_executable_batch_size(                                 [31m│
[31m│[39m   1407 │   │   │   [96mself[39m._inner_training_loop, [96mself[39m._train_batch_size, args.auto_find_batch_size  [31m│
[31m│[39m   1408 │   │   )                                                                                 [31m│
[31m│[39m [31m❱ [39m1409 │   │   [94mreturn[39m inner_training_loop(                                                       [31m│
[31m│[39m   1410 │   │   │   args=args,                                                                    [31m│
[31m│[39m   1411 │   │   │   resume_from_checkpoint=resume_from_checkpoint,                                [31m│
[31m│[39m   1412 │   │   │   trial=trial,                                                                  [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/[1mtrainer.py[22m:[94m1651[39m in  [31m│
[31m│[39m [92m_inner_training_loop[39m                                                                             [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m   1648 │   │   │   │   │   [94mwith[39m model.no_sync():                                                 [31m│
[31m│[39m   1649 │   │   │   │   │   │   tr_loss_step = [96mself[39m.training_step(model, inputs)                  [31m│
[31m│[39m   1650 │   │   │   │   [94melse[39m:                                                                     [31m│
[31m│[39m [31m❱ [39m1651 │   │   │   │   │   tr_loss_step = [96mself[39m.training_step(model, inputs)                      [31m│
[31m│[39m   1652 │   │   │   │                                                                             [31m│
[31m│[39m   1653 │   │   │   │   [94mif[39m (                                                                      [31m│
[31m│[39m   1654 │   │   │   │   │   args.logging_nan_inf_filter                                           [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/[1mtrainer.py[22m:[94m2345[39m in  [31m│
[31m│[39m [92mtraining_step[39m                                                                                    [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m   2342 │   │   │   [94mreturn[39m loss_mb.reduce_mean().detach().to([96mself[39m.args.device)                    [31m│
[31m│[39m   2343 │   │                                                                                     [31m│
[31m│[39m   2344 │   │   [94mwith[39m [96mself[39m.compute_loss_context_manager():                                         [31m│
[31m│[39m [31m❱ [39m2345 │   │   │   loss = [96mself[39m.compute_loss(model, inputs)                                       [31m│
[31m│[39m   2346 │   │                                                                                     [31m│
[31m│[39m   2347 │   │   [94mif[39m [96mself[39m.args.n_gpu > [94m1[39m:                                                           [31m│
[31m│[39m   2348 │   │   │   loss = loss.mean()  # mean() to average on multi-gpu parallel training        [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/[1mtrainer.py[22m:[94m2377[39m in  [31m│
[31m│[39m [92mcompute_loss[39m                                                                                     [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m   2374 │   │   │   labels = inputs.pop([33m"labels"[39m)                                                 [31m│
[31m│[39m   2375 │   │   [94melse[39m:                                                                             [31m│
[31m│[39m   2376 │   │   │   labels = [94mNone[39m                                                                 [31m│
[31m│[39m [31m❱ [39m2377 │   │   outputs = model(**inputs)                                                         [31m│
[31m│[39m   2378 │   │   # Save past state if it exists                                                    [31m│
[31m│[39m   2379 │   │   # TODO: this needs to be fixed and made cleaner later.                            [31m│
[31m│[39m   2380 │   │   [94mif[39m [96mself[39m.args.past_index >= [94m0[39m:                                                     [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m1130[39m  [31m│
[31m│[39m in [92m_call_impl[39m                                                                                    [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m   1127 │   │   # this function, and just call forward.                                           [31m│
[31m│[39m   1128 │   │   [94mif[39m [95mnot[39m ([96mself[39m._backward_hooks [95mor[39m [96mself[39m._forward_hooks [95mor[39m [96mself[39m._forward_pre_hooks [95mo[39m  [31m│
[31m│[39m   1129 │   │   │   │   [95mor[39m _global_forward_hooks [95mor[39m _global_forward_pre_hooks):                   [31m│
[31m│[39m [31m❱ [39m1130 │   │   │   [94mreturn[39m forward_call(*[96minput[39m, **kwargs)                                         [31m│
[31m│[39m   1131 │   │   # Do not call functions when jit is used                                          [31m│
[31m│[39m   1132 │   │   full_backward_hooks, non_full_backward_hooks = [], []                             [31m│
[31m│[39m   1133 │   │   [94mif[39m [96mself[39m._backward_hooks [95mor[39m _global_backward_hooks:                                [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/transformers/models/gptj/[1mmodelin[22m [31m│
[31m│[39m [1mg_gptj.py[22m:[94m848[39m in [92mforward[39m                                                                         [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m    845 │   │   │   shift_labels = labels[..., [94m1[39m:].contiguous()                                   [31m│
[31m│[39m    846 │   │   │   # Flatten the tokens                                                          [31m│
[31m│[39m    847 │   │   │   loss_fct = CrossEntropyLoss()                                                 [31m│
[31m│[39m [31m❱ [39m 848 │   │   │   loss = loss_fct(shift_logits.view(-[94m1[39m, shift_logits.size(-[94m1[39m)), shift_labels.v  [31m│
[31m│[39m    849 │   │   │                                                                                 [31m│
[31m│[39m    850 │   │   │   loss = loss.to(hidden_states.dtype)                                           [31m│
[31m│[39m    851                                                                                           [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/[1mmodule.py[22m:[94m1130[39m  [31m│
[31m│[39m in [92m_call_impl[39m                                                                                    [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m   1127 │   │   # this function, and just call forward.                                           [31m│
[31m│[39m   1128 │   │   [94mif[39m [95mnot[39m ([96mself[39m._backward_hooks [95mor[39m [96mself[39m._forward_hooks [95mor[39m [96mself[39m._forward_pre_hooks [95mo[39m  [31m│
[31m│[39m   1129 │   │   │   │   [95mor[39m _global_forward_hooks [95mor[39m _global_forward_pre_hooks):                   [31m│
[31m│[39m [31m❱ [39m1130 │   │   │   [94mreturn[39m forward_call(*[96minput[39m, **kwargs)                                         [31m│
[31m│[39m   1131 │   │   # Do not call functions when jit is used                                          [31m│
[31m│[39m   1132 │   │   full_backward_hooks, non_full_backward_hooks = [], []                             [31m│
[31m│[39m   1133 │   │   [94mif[39m [96mself[39m._backward_hooks [95mor[39m _global_backward_hooks:                                [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/modules/[1mloss.py[22m:[94m1164[39m in [31m│
[31m│[39m [92mforward[39m                                                                                          [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m   1161 │   │   [96mself[39m.label_smoothing = label_smoothing                                            [31m│
[31m│[39m   1162 │                                                                                         [31m│
[31m│[39m   1163 │   [94mdef[39m [92mforward[39m([96mself[39m, [96minput[39m: Tensor, target: Tensor) -> Tensor:                           [31m│
[31m│[39m [31m❱ [39m1164 │   │   [94mreturn[39m F.cross_entropy([96minput[39m, target, weight=[96mself[39m.weight,                         [31m│
[31m│[39m   1165 │   │   │   │   │   │   │      ignore_index=[96mself[39m.ignore_index, reduction=[96mself[39m.reduction,  [31m│
[31m│[39m   1166 │   │   │   │   │   │   │      label_smoothing=[96mself[39m.label_smoothing)                      [31m│
[31m│[39m   1167                                                                                           [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m /home/ailab/anaconda3/envs/py38_env/lib/python3.8/site-packages/torch/nn/[1mfunctional.py[22m:[94m3014[39m in   [31m│
[31m│[39m [92mcross_entropy[39m                                                                                    [31m│
[31m│[39m                                                                                                  [31m│
[31m│[39m   3011 │   │   )                                                                                 [31m│
[31m│[39m   3012 │   [94mif[39m size_average [95mis[39m [95mnot[39m [94mNone[39m [95mor[39m reduce [95mis[39m [95mnot[39m [94mNone[39m:                                    [31m│
[31m│[39m   3013 │   │   reduction = _Reduction.legacy_get_string(size_average, reduce)                    [31m│
[31m│[39m [31m❱ [39m3014 │   [94mreturn[39m torch._C._nn.cross_entropy_loss([96minput[39m, target, weight, _Reduction.get_enum(re  [31m│
[31m│[39m   3015                                                                                           [31m│
[31m│[39m   3016                                                                                           [31m│
[31m│[39m   3017 [94mdef[39m [92mbinary_cross_entropy[39m(                                                                 [31m│
[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
[1mValueError: [22mExpected input batch_size [1m(96)[22m to match target batch_size [1m(1088)[22m.